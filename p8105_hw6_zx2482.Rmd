---
title: "p8105_hw6_zx2482"
author: "Allison Xia"
date: "2023-12-02"
output: github_document
---

```{r}
library(readr)
library(dplyr)
library(stringr)
library(modelr)
```

## Problem 1

```{r echo = FALSE}
# URL of the dataset
url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

# Reading the dataset
homicide_data <- read_csv(url)

```
```{r}
# Create a city_state variable
homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", "))

# Create a binary variable for solved homicides
homicide_data <- homicide_data %>%
  mutate(solved_binary = ifelse(disposition == "Closed by arrest", 1, 0))

# Omit specified cities
homicide_data <- homicide_data %>%
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) 

# Limit analysis to cases where victim_race is white or black
homicide_data <- homicide_data %>%
  filter(victim_race %in% c("White", "Black"))

# Ensure victim_age is numeric
homicide_data$victim_age <- as.numeric(homicide_data$victim_age)

# View the modified dataset
head(homicide_data)
```

```{r}
# Filter data for Baltimore, MD
baltimore_data <- homicide_data %>%
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model
model <- glm(solved_binary ~ victim_age + victim_sex + victim_race, 
             data = baltimore_data, family = binomial())

# Extract adjusted odds ratio for male vs female victims
# Calculate OR confidence interval
model |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

Below, by incorporating `nest()`, `map()`, and `unnest()` into the preceding Baltimore-specific code, we fit a model for each of the cities, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. We show the first 5 rows of the resulting dataframe of model results.

```{r q1_glm_all_cities}
model_results = 
  homicide_data |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(solved_binary ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

Below we generate a plot of the estimated ORs and CIs for each city, ordered by magnitude of the OR from smallest to largest. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race. 

```{r q1_plot}
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Problem 2

```{r download data}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
str(weather_df)
```

```{r create bootstrap samples}
set.seed(1202)

boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

weather_samples = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(df = weather_df)),
    models=map(strap_sample,\(df) lm(tmax~tmin+prcp,data=df))
  )
```

```{r r.squared_estimates}
r_squared_estimates = 
  weather_samples |> 
  mutate(
    results=map(models,broom::glance)
  )|>
  select(-strap_sample,-models)|>
  unnest(results)|>
  select(strap_number,r.squared)
```


```{r r.squared_estimates_plot}
r_squared_estimates |> 
ggplot(aes(x=r.squared))+
  geom_density()+
  labs(
    title="r.squared estimates for 5000 bootstrap samples"
  )
```

```{r log_1_log_2_estimates}
log_estimates = 
  weather_samples|>
  mutate(
    models=map(strap_sample,\(df) lm(tmax~tmin+prcp,data=df)),
    results=map(models,broom::tidy)
  )|>
  select(-strap_sample,-models)|>
  unnest(results)|>
  select(strap_number,term,estimate)|>
  filter(term %in% c("tmin","prcp"))|>
  group_by(strap_number)|>
  summarise(log_b1_b2=log(prod(estimate)))
```
```{r}
log_estimates |> 
  ggplot(aes(x=log_b1_b2))+
  geom_density()+
  labs(
    title="log(beta1*beta2) estimates for 5000 bootstrap samples"
  )
```



